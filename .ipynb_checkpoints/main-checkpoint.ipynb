{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def get_latest_epoch():\n",
    "    models = os.listdir(\"./model\")\n",
    "    all_epochs = [int(model[model.find(\"-\")+1:].replace(\".meta\",\"\")) for model in models if \"meta\" in model]\n",
    "    return max(all_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0,
     11,
     17
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260539, 50, 111) (260539, 111)\n"
     ]
    }
   ],
   "source": [
    "# initialise text variables\n",
    "data_file = \"./data/all_scripts.txt\"\n",
    "text = open(data_file).read().strip()\n",
    "vocab = sorted(list(set(text)))\n",
    "vocab_length = len(vocab)\n",
    "characters2id = dict((c, i) for i, c in enumerate(vocab))\n",
    "id2characters = dict((i, c) for i, c in enumerate(vocab))\n",
    "section_length = 50\n",
    "step = 10\n",
    "sections = []\n",
    "section_labels = []\n",
    "for i in range(0,len(text)-section_length,step):\n",
    "    sections.append(text[i:i+section_length])\n",
    "    section_labels.append(text[i+section_length])\n",
    "\n",
    "X_data = np.zeros((len(sections),section_length,vocab_length))\n",
    "Y_data = np.zeros((len(sections),vocab_length))\n",
    "for i,section in enumerate(sections):\n",
    "    for j,letter in enumerate(section):\n",
    "        X_data[i,j,characters2id[letter]] = 1\n",
    "    Y_data[i,characters2id[section_labels[i]]] = 1\n",
    "\n",
    "print(X_data.shape,Y_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "total_epochs = 500\n",
    "batch_size = 128\n",
    "log_every = 100\n",
    "save_every = 10\n",
    "hidden_nodes = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32,[None,section_length,vocab_length],name=\"X_train\")\n",
    "Y = tf.placeholder(tf.float32,[None,vocab_length],name=\"Y_train\")\n",
    "\n",
    "W = tf.Variable(tf.random_normal([hidden_nodes,vocab_length]),name=\"Output_weights\")\n",
    "b = tf.Variable(tf.random_normal([vocab_length]),name=\"Output_bias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm(x,weights,bias):\n",
    "    x = tf.unstack(x,section_length,1)\n",
    "    lstm_cell = tf.contrib.rnn.BasicLSTMCell(hidden_nodes,forget_bias=1.0)\n",
    "    outputs, states = tf.contrib.rnn.static_rnn(lstm_cell, x, dtype=tf.float32)\n",
    "    return tf.matmul(outputs[-1],W)+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = lstm(X,W,b)\n",
    "prediction = tf.nn.softmax(logits)\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)\n",
    "\n",
    "correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver(max_to_keep=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resuming training from epoch: 300\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-300\n",
      "Epoch: 0\n",
      "Step 0, Minibatch Loss= 0.3911, Training Accuracy= 0.930\n",
      "Step 100, Minibatch Loss= 0.4538, Training Accuracy= 0.898\n",
      "Step 200, Minibatch Loss= 0.4262, Training Accuracy= 0.930\n",
      "Step 300, Minibatch Loss= 1.1867, Training Accuracy= 0.672\n",
      "Step 400, Minibatch Loss= 0.6267, Training Accuracy= 0.875\n",
      "Step 500, Minibatch Loss= 0.6766, Training Accuracy= 0.789\n",
      "Step 600, Minibatch Loss= 0.8186, Training Accuracy= 0.781\n",
      "Step 700, Minibatch Loss= 0.5516, Training Accuracy= 0.859\n",
      "Step 800, Minibatch Loss= 0.7460, Training Accuracy= 0.797\n",
      "Step 900, Minibatch Loss= 0.7315, Training Accuracy= 0.812\n",
      "Step 1000, Minibatch Loss= 0.8028, Training Accuracy= 0.797\n",
      "Step 1100, Minibatch Loss= 0.7253, Training Accuracy= 0.820\n",
      "Step 1200, Minibatch Loss= 0.5804, Training Accuracy= 0.883\n",
      "Step 1300, Minibatch Loss= 0.6306, Training Accuracy= 0.797\n",
      "Step 1400, Minibatch Loss= 0.4083, Training Accuracy= 0.906\n",
      "Step 1500, Minibatch Loss= 0.5513, Training Accuracy= 0.906\n",
      "Step 1600, Minibatch Loss= 0.5122, Training Accuracy= 0.852\n",
      "Step 1700, Minibatch Loss= 0.6536, Training Accuracy= 0.836\n",
      "Step 1800, Minibatch Loss= 0.2317, Training Accuracy= 0.953\n",
      "Step 1900, Minibatch Loss= 0.5286, Training Accuracy= 0.867\n",
      "Step 2000, Minibatch Loss= 0.8261, Training Accuracy= 0.797\n",
      "INFO:tensorflow:./model/model.ckpt-300 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Model saved in file: ./model/model.ckpt-300\n",
      "Epoch: 1\n",
      "Step 0, Minibatch Loss= 0.3782, Training Accuracy= 0.938\n",
      "Step 100, Minibatch Loss= 0.4481, Training Accuracy= 0.898\n",
      "Step 200, Minibatch Loss= 0.4228, Training Accuracy= 0.930\n",
      "Step 300, Minibatch Loss= 1.1687, Training Accuracy= 0.680\n",
      "Step 400, Minibatch Loss= 0.5943, Training Accuracy= 0.883\n",
      "Step 500, Minibatch Loss= 0.6463, Training Accuracy= 0.812\n",
      "Step 600, Minibatch Loss= 0.7890, Training Accuracy= 0.789\n",
      "Step 700, Minibatch Loss= 0.5212, Training Accuracy= 0.883\n",
      "Step 800, Minibatch Loss= 0.7429, Training Accuracy= 0.797\n",
      "Step 900, Minibatch Loss= 0.6792, Training Accuracy= 0.812\n",
      "Step 1000, Minibatch Loss= 0.7685, Training Accuracy= 0.797\n",
      "Step 1100, Minibatch Loss= 0.6788, Training Accuracy= 0.828\n",
      "Step 1200, Minibatch Loss= 0.5907, Training Accuracy= 0.875\n",
      "Step 1300, Minibatch Loss= 0.6332, Training Accuracy= 0.820\n",
      "Step 1400, Minibatch Loss= 0.3582, Training Accuracy= 0.922\n",
      "Step 1500, Minibatch Loss= 0.5044, Training Accuracy= 0.906\n",
      "Step 1600, Minibatch Loss= 0.5514, Training Accuracy= 0.844\n",
      "Step 1700, Minibatch Loss= 0.6351, Training Accuracy= 0.836\n",
      "Step 1800, Minibatch Loss= 0.2181, Training Accuracy= 0.953\n",
      "Step 1900, Minibatch Loss= 0.4985, Training Accuracy= 0.898\n",
      "Step 2000, Minibatch Loss= 0.8337, Training Accuracy= 0.789\n",
      "Epoch: 2\n",
      "Step 0, Minibatch Loss= 0.3752, Training Accuracy= 0.922\n",
      "Step 100, Minibatch Loss= 0.4223, Training Accuracy= 0.914\n",
      "Step 200, Minibatch Loss= 0.4051, Training Accuracy= 0.930\n",
      "Step 300, Minibatch Loss= 1.1528, Training Accuracy= 0.680\n",
      "Step 400, Minibatch Loss= 0.5848, Training Accuracy= 0.875\n",
      "Step 500, Minibatch Loss= 0.6127, Training Accuracy= 0.836\n",
      "Step 600, Minibatch Loss= 0.7753, Training Accuracy= 0.797\n",
      "Step 700, Minibatch Loss= 0.4839, Training Accuracy= 0.883\n",
      "Step 800, Minibatch Loss= 0.7314, Training Accuracy= 0.805\n",
      "Step 900, Minibatch Loss= 0.6604, Training Accuracy= 0.820\n",
      "Step 1000, Minibatch Loss= 0.7625, Training Accuracy= 0.805\n",
      "Step 1100, Minibatch Loss= 0.6899, Training Accuracy= 0.820\n",
      "Step 1200, Minibatch Loss= 0.5439, Training Accuracy= 0.906\n",
      "Step 1300, Minibatch Loss= 0.6013, Training Accuracy= 0.820\n",
      "Step 1400, Minibatch Loss= 0.3724, Training Accuracy= 0.891\n",
      "Step 1500, Minibatch Loss= 0.4865, Training Accuracy= 0.922\n",
      "Step 1600, Minibatch Loss= 0.5141, Training Accuracy= 0.836\n",
      "Step 1700, Minibatch Loss= 0.5549, Training Accuracy= 0.836\n",
      "Step 1800, Minibatch Loss= 0.2430, Training Accuracy= 0.945\n",
      "Step 1900, Minibatch Loss= 0.4870, Training Accuracy= 0.906\n",
      "Step 2000, Minibatch Loss= 0.7569, Training Accuracy= 0.797\n",
      "Epoch: 3\n",
      "Step 0, Minibatch Loss= 0.3290, Training Accuracy= 0.945\n",
      "Step 100, Minibatch Loss= 0.4234, Training Accuracy= 0.898\n",
      "Step 200, Minibatch Loss= 0.3934, Training Accuracy= 0.930\n",
      "Step 300, Minibatch Loss= 1.1105, Training Accuracy= 0.656\n",
      "Step 400, Minibatch Loss= 0.5649, Training Accuracy= 0.875\n",
      "Step 500, Minibatch Loss= 0.6169, Training Accuracy= 0.859\n",
      "Step 600, Minibatch Loss= 0.7541, Training Accuracy= 0.797\n",
      "Step 700, Minibatch Loss= 0.4807, Training Accuracy= 0.883\n",
      "Step 800, Minibatch Loss= 0.7325, Training Accuracy= 0.789\n",
      "Step 900, Minibatch Loss= 0.6317, Training Accuracy= 0.844\n",
      "Step 1000, Minibatch Loss= 0.7306, Training Accuracy= 0.805\n",
      "Step 1100, Minibatch Loss= 0.6478, Training Accuracy= 0.836\n",
      "Step 1200, Minibatch Loss= 0.5289, Training Accuracy= 0.883\n",
      "Step 1300, Minibatch Loss= 0.5737, Training Accuracy= 0.820\n",
      "Step 1400, Minibatch Loss= 0.3604, Training Accuracy= 0.922\n",
      "Step 1500, Minibatch Loss= 0.4651, Training Accuracy= 0.914\n",
      "Step 1600, Minibatch Loss= 0.5262, Training Accuracy= 0.883\n",
      "Step 1700, Minibatch Loss= 0.5571, Training Accuracy= 0.852\n",
      "Step 1800, Minibatch Loss= 0.1980, Training Accuracy= 0.969\n",
      "Step 1900, Minibatch Loss= 0.4501, Training Accuracy= 0.906\n",
      "Step 2000, Minibatch Loss= 0.7567, Training Accuracy= 0.797\n",
      "Epoch: 4\n",
      "Step 0, Minibatch Loss= 0.3139, Training Accuracy= 0.961\n",
      "Step 100, Minibatch Loss= 0.4094, Training Accuracy= 0.922\n",
      "Step 200, Minibatch Loss= 0.3951, Training Accuracy= 0.922\n",
      "Step 300, Minibatch Loss= 1.0912, Training Accuracy= 0.688\n",
      "Step 400, Minibatch Loss= 0.5697, Training Accuracy= 0.891\n",
      "Step 500, Minibatch Loss= 0.5796, Training Accuracy= 0.852\n",
      "Step 600, Minibatch Loss= 0.7003, Training Accuracy= 0.828\n",
      "Step 700, Minibatch Loss= 0.4687, Training Accuracy= 0.883\n",
      "Step 800, Minibatch Loss= 0.6720, Training Accuracy= 0.820\n",
      "Step 900, Minibatch Loss= 0.6062, Training Accuracy= 0.836\n",
      "Step 1000, Minibatch Loss= 0.7019, Training Accuracy= 0.828\n",
      "Step 1100, Minibatch Loss= 0.6161, Training Accuracy= 0.844\n",
      "Step 1200, Minibatch Loss= 0.5139, Training Accuracy= 0.906\n",
      "Step 1300, Minibatch Loss= 0.5418, Training Accuracy= 0.836\n",
      "Step 1400, Minibatch Loss= 0.4109, Training Accuracy= 0.922\n",
      "Step 1500, Minibatch Loss= 0.4203, Training Accuracy= 0.922\n",
      "Step 1600, Minibatch Loss= 0.4736, Training Accuracy= 0.859\n",
      "Step 1700, Minibatch Loss= 0.5480, Training Accuracy= 0.867\n",
      "Step 1800, Minibatch Loss= 0.2017, Training Accuracy= 0.969\n",
      "Step 1900, Minibatch Loss= 0.3895, Training Accuracy= 0.906\n",
      "Step 2000, Minibatch Loss= 0.7049, Training Accuracy= 0.812\n",
      "Epoch: 5\n",
      "Step 0, Minibatch Loss= 0.3233, Training Accuracy= 0.930\n",
      "Step 100, Minibatch Loss= 0.3764, Training Accuracy= 0.922\n",
      "Step 200, Minibatch Loss= 0.3612, Training Accuracy= 0.945\n",
      "Step 300, Minibatch Loss= 1.1202, Training Accuracy= 0.711\n",
      "Step 400, Minibatch Loss= 0.5270, Training Accuracy= 0.922\n",
      "Step 500, Minibatch Loss= 0.4984, Training Accuracy= 0.891\n",
      "Step 600, Minibatch Loss= 0.6823, Training Accuracy= 0.828\n",
      "Step 700, Minibatch Loss= 0.4287, Training Accuracy= 0.906\n",
      "Step 800, Minibatch Loss= 0.6521, Training Accuracy= 0.820\n",
      "Step 900, Minibatch Loss= 0.5898, Training Accuracy= 0.836\n",
      "Step 1000, Minibatch Loss= 0.7025, Training Accuracy= 0.828\n",
      "Step 1100, Minibatch Loss= 0.5977, Training Accuracy= 0.828\n",
      "Step 1200, Minibatch Loss= 0.5034, Training Accuracy= 0.891\n",
      "Step 1300, Minibatch Loss= 0.5374, Training Accuracy= 0.836\n",
      "Step 1400, Minibatch Loss= 0.3287, Training Accuracy= 0.930\n",
      "Step 1500, Minibatch Loss= 0.4057, Training Accuracy= 0.930\n",
      "Step 1600, Minibatch Loss= 0.5176, Training Accuracy= 0.828\n",
      "Step 1700, Minibatch Loss= 0.5580, Training Accuracy= 0.844\n",
      "Step 1800, Minibatch Loss= 0.1764, Training Accuracy= 0.977\n",
      "Step 1900, Minibatch Loss= 0.4068, Training Accuracy= 0.922\n",
      "Step 2000, Minibatch Loss= 0.7204, Training Accuracy= 0.789\n",
      "Epoch: 6\n",
      "Step 0, Minibatch Loss= 0.2971, Training Accuracy= 0.953\n",
      "Step 100, Minibatch Loss= 0.3383, Training Accuracy= 0.930\n",
      "Step 200, Minibatch Loss= 0.3153, Training Accuracy= 0.945\n",
      "Step 300, Minibatch Loss= 1.0757, Training Accuracy= 0.695\n",
      "Step 400, Minibatch Loss= 0.5083, Training Accuracy= 0.914\n",
      "Step 500, Minibatch Loss= 0.5179, Training Accuracy= 0.891\n",
      "Step 600, Minibatch Loss= 0.6441, Training Accuracy= 0.828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 700, Minibatch Loss= 0.4325, Training Accuracy= 0.898\n",
      "Step 800, Minibatch Loss= 0.6288, Training Accuracy= 0.828\n",
      "Step 900, Minibatch Loss= 0.5472, Training Accuracy= 0.875\n",
      "Step 1000, Minibatch Loss= 0.6767, Training Accuracy= 0.812\n",
      "Step 1100, Minibatch Loss= 0.5260, Training Accuracy= 0.859\n",
      "Step 1200, Minibatch Loss= 0.4763, Training Accuracy= 0.891\n",
      "Step 1300, Minibatch Loss= 0.5509, Training Accuracy= 0.844\n",
      "Step 1400, Minibatch Loss= 0.3148, Training Accuracy= 0.914\n",
      "Step 1500, Minibatch Loss= 0.4002, Training Accuracy= 0.922\n",
      "Step 1600, Minibatch Loss= 0.4233, Training Accuracy= 0.875\n",
      "Step 1700, Minibatch Loss= 0.5246, Training Accuracy= 0.852\n",
      "Step 1800, Minibatch Loss= 0.1745, Training Accuracy= 0.969\n",
      "Step 1900, Minibatch Loss= 0.4042, Training Accuracy= 0.906\n",
      "Step 2000, Minibatch Loss= 0.6952, Training Accuracy= 0.805\n",
      "Epoch: 7\n",
      "Step 0, Minibatch Loss= 0.2653, Training Accuracy= 0.969\n",
      "Step 100, Minibatch Loss= 0.3401, Training Accuracy= 0.930\n",
      "Step 200, Minibatch Loss= 0.2878, Training Accuracy= 0.945\n",
      "Step 300, Minibatch Loss= 1.0351, Training Accuracy= 0.734\n",
      "Step 400, Minibatch Loss= 0.4637, Training Accuracy= 0.914\n",
      "Step 500, Minibatch Loss= 0.4604, Training Accuracy= 0.891\n",
      "Step 600, Minibatch Loss= 0.6269, Training Accuracy= 0.836\n",
      "Step 700, Minibatch Loss= 0.4448, Training Accuracy= 0.883\n",
      "Step 800, Minibatch Loss= 0.6094, Training Accuracy= 0.828\n",
      "Step 900, Minibatch Loss= 0.5640, Training Accuracy= 0.852\n",
      "Step 1000, Minibatch Loss= 0.6610, Training Accuracy= 0.820\n",
      "Step 1100, Minibatch Loss= 0.5570, Training Accuracy= 0.859\n",
      "Step 1200, Minibatch Loss= 0.4579, Training Accuracy= 0.891\n",
      "Step 1300, Minibatch Loss= 0.5247, Training Accuracy= 0.844\n",
      "Step 1400, Minibatch Loss= 0.3008, Training Accuracy= 0.922\n",
      "Step 1500, Minibatch Loss= 0.3804, Training Accuracy= 0.938\n",
      "Step 1600, Minibatch Loss= 0.4082, Training Accuracy= 0.867\n",
      "Step 1700, Minibatch Loss= 0.4760, Training Accuracy= 0.883\n",
      "Step 1800, Minibatch Loss= 0.1787, Training Accuracy= 0.969\n",
      "Step 1900, Minibatch Loss= 0.3864, Training Accuracy= 0.922\n",
      "Step 2000, Minibatch Loss= 0.6353, Training Accuracy= 0.844\n",
      "Epoch: 8\n",
      "Step 0, Minibatch Loss= 0.2656, Training Accuracy= 0.969\n",
      "Step 100, Minibatch Loss= 0.3164, Training Accuracy= 0.938\n",
      "Step 200, Minibatch Loss= 0.2910, Training Accuracy= 0.953\n",
      "Step 300, Minibatch Loss= 1.0279, Training Accuracy= 0.688\n",
      "Step 400, Minibatch Loss= 0.4636, Training Accuracy= 0.914\n",
      "Step 500, Minibatch Loss= 0.4849, Training Accuracy= 0.906\n",
      "Step 600, Minibatch Loss= 0.6186, Training Accuracy= 0.836\n",
      "Step 700, Minibatch Loss= 0.4012, Training Accuracy= 0.898\n",
      "Step 800, Minibatch Loss= 0.5940, Training Accuracy= 0.828\n",
      "Step 900, Minibatch Loss= 0.5222, Training Accuracy= 0.852\n",
      "Step 1000, Minibatch Loss= 0.6458, Training Accuracy= 0.844\n",
      "Step 1100, Minibatch Loss= 0.5156, Training Accuracy= 0.875\n",
      "Step 1200, Minibatch Loss= 0.4303, Training Accuracy= 0.891\n",
      "Step 1300, Minibatch Loss= 0.4999, Training Accuracy= 0.859\n",
      "Step 1400, Minibatch Loss= 0.3340, Training Accuracy= 0.922\n",
      "Step 1500, Minibatch Loss= 0.3638, Training Accuracy= 0.930\n",
      "Step 1600, Minibatch Loss= 0.3952, Training Accuracy= 0.898\n",
      "Step 1700, Minibatch Loss= 0.4369, Training Accuracy= 0.898\n",
      "Step 1800, Minibatch Loss= 0.1671, Training Accuracy= 0.969\n",
      "Step 1900, Minibatch Loss= 0.3663, Training Accuracy= 0.922\n",
      "Step 2000, Minibatch Loss= 0.5781, Training Accuracy= 0.883\n",
      "Epoch: 9\n",
      "Step 0, Minibatch Loss= 0.2767, Training Accuracy= 0.961\n",
      "Step 100, Minibatch Loss= 0.2771, Training Accuracy= 0.945\n",
      "Step 200, Minibatch Loss= 0.2899, Training Accuracy= 0.953\n",
      "Step 300, Minibatch Loss= 1.0007, Training Accuracy= 0.719\n",
      "Step 400, Minibatch Loss= 0.4150, Training Accuracy= 0.938\n",
      "Step 500, Minibatch Loss= 0.4487, Training Accuracy= 0.891\n",
      "Step 600, Minibatch Loss= 0.5854, Training Accuracy= 0.844\n",
      "Step 700, Minibatch Loss= 0.3709, Training Accuracy= 0.914\n",
      "Step 800, Minibatch Loss= 0.5609, Training Accuracy= 0.828\n",
      "Step 900, Minibatch Loss= 0.4966, Training Accuracy= 0.875\n",
      "Step 1000, Minibatch Loss= 0.6492, Training Accuracy= 0.828\n",
      "Step 1100, Minibatch Loss= 0.4877, Training Accuracy= 0.867\n",
      "Step 1200, Minibatch Loss= 0.4120, Training Accuracy= 0.930\n",
      "Step 1300, Minibatch Loss= 0.4644, Training Accuracy= 0.852\n",
      "Step 1400, Minibatch Loss= 0.3368, Training Accuracy= 0.930\n",
      "Step 1500, Minibatch Loss= 0.3586, Training Accuracy= 0.938\n",
      "Step 1600, Minibatch Loss= 0.4005, Training Accuracy= 0.898\n",
      "Step 1700, Minibatch Loss= 0.4576, Training Accuracy= 0.875\n",
      "Step 1800, Minibatch Loss= 0.1598, Training Accuracy= 0.977\n",
      "Step 1900, Minibatch Loss= 0.2980, Training Accuracy= 0.945\n",
      "Step 2000, Minibatch Loss= 0.6197, Training Accuracy= 0.859\n",
      "Epoch: 10\n",
      "Step 0, Minibatch Loss= 0.2357, Training Accuracy= 0.961\n",
      "Step 100, Minibatch Loss= 0.3123, Training Accuracy= 0.945\n",
      "Step 200, Minibatch Loss= 0.2727, Training Accuracy= 0.953\n",
      "Step 300, Minibatch Loss= 0.9747, Training Accuracy= 0.727\n",
      "Step 400, Minibatch Loss= 0.4119, Training Accuracy= 0.922\n",
      "Step 500, Minibatch Loss= 0.3916, Training Accuracy= 0.906\n",
      "Step 600, Minibatch Loss= 0.5601, Training Accuracy= 0.844\n",
      "Step 700, Minibatch Loss= 0.3264, Training Accuracy= 0.938\n",
      "Step 800, Minibatch Loss= 0.5047, Training Accuracy= 0.867\n",
      "Step 900, Minibatch Loss= 0.4995, Training Accuracy= 0.891\n",
      "Step 1000, Minibatch Loss= 0.6096, Training Accuracy= 0.859\n",
      "Step 1100, Minibatch Loss= 0.4635, Training Accuracy= 0.883\n",
      "Step 1200, Minibatch Loss= 0.4037, Training Accuracy= 0.898\n",
      "Step 1300, Minibatch Loss= 0.4448, Training Accuracy= 0.852\n",
      "Step 1400, Minibatch Loss= 0.2501, Training Accuracy= 0.938\n",
      "Step 1500, Minibatch Loss= 0.3514, Training Accuracy= 0.961\n",
      "Step 1600, Minibatch Loss= 0.4750, Training Accuracy= 0.867\n",
      "Step 1700, Minibatch Loss= 0.3838, Training Accuracy= 0.922\n",
      "Step 1800, Minibatch Loss= 0.1897, Training Accuracy= 0.969\n",
      "Step 1900, Minibatch Loss= 0.2990, Training Accuracy= 0.953\n",
      "Step 2000, Minibatch Loss= 0.6014, Training Accuracy= 0.859\n",
      "INFO:tensorflow:./model/model.ckpt-310 is not in all_model_checkpoint_paths. Manually adding it.\n",
      "Model saved in file: ./model/model.ckpt-310\n",
      "Epoch: 11\n",
      "Step 0, Minibatch Loss= 0.2103, Training Accuracy= 0.977\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-11d9989408d5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mbatch_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mbatch_Y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_i\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_Y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbatch_i\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mlog_every\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "epoch_start = get_latest_epoch()\n",
    "print(\"Resuming training from epoch: {}\".format(epoch_start))\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    saver.restore(sess,\"./model/model.ckpt-\"+str(epoch_start))\n",
    "    for epoch in range(total_epochs):\n",
    "        print(\"Epoch: {}\".format(epoch) )\n",
    "        for batch_i in range(len(X_data)/batch_size):\n",
    "            batch_X = X_data[batch_i*batch_size:(batch_i+1)*batch_size]\n",
    "            batch_Y = Y_data[batch_i*batch_size:(batch_i+1)*batch_size]\n",
    "            sess.run(train_op,feed_dict={X:batch_X,Y:batch_Y})\n",
    "            \n",
    "            if batch_i%log_every == 0:\n",
    "                loss, acc = sess.run([loss_op, accuracy], feed_dict={X: batch_X,Y: batch_Y})\n",
    "                print(\"Step \" + str(batch_i) + \", Minibatch Loss= \" + \\\n",
    "                      \"{:.4f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.3f}\".format(acc))\n",
    "        if epoch%save_every == 0:\n",
    "            save_path = saver.save(sess, \"./model/model.ckpt\",global_step=epoch+epoch_start)\n",
    "            print(\"Model saved in file: %s\" % save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample2(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing epoch: 310\n",
      "INFO:tensorflow:Restoring parameters from ./model/model.ckpt-310\n",
      "Temperature = 0.2\n",
      "th his arms\n",
      "raised.\n",
      "\n",
      "DAMIEN\n",
      "Death to the holy! The2 0.883112\n",
      "[  3.52064428e-12   5.58574870e-03   8.83111835e-01   9.69314442e-06\n",
      "   3.15529746e-07   1.30883998e-10   1.65024854e-14   1.71597477e-13\n",
      "   1.24183075e-09   5.55843487e-03   5.60243421e-13   1.14091740e-11\n",
      "   4.96136173e-13   8.30597581e-13   1.06752123e-04   4.48671273e-07\n",
      "   4.31381741e-05   1.15544442e-13   2.56972328e-08   1.21400726e-14\n",
      "   2.54036213e-15   3.10716487e-16   3.11743491e-12   2.14141842e-13\n",
      "   3.43843964e-12   1.60762686e-14   4.83548693e-18   8.94899443e-13\n",
      "   4.04324130e-09   2.84546001e-16   5.65778327e-12   1.34906963e-09\n",
      "   3.50028500e-07   6.91549736e-13   1.02955555e-08   3.07132950e-08\n",
      "   1.03464199e-05   3.28676197e-09   8.04239786e-10   1.44593386e-08\n",
      "   7.39034250e-11   4.20221280e-09   7.15301383e-07   2.34256170e-10\n",
      "   2.30660220e-08   1.02522144e-07   9.76554375e-08   3.22840918e-08\n",
      "   4.84385865e-11   4.87625948e-06   1.36330808e-11   2.24010346e-05\n",
      "   4.39038716e-09   2.63284096e-06   1.32713562e-10   2.12563791e-05\n",
      "   2.28599384e-09   2.59269717e-10   8.93567054e-10   2.30587194e-08\n",
      "   1.46679245e-15   2.07986961e-09   3.13621389e-13   1.99948703e-11\n",
      "   1.50046626e-03   5.11549297e-06   2.51627527e-03   7.32165063e-07\n",
      "   5.54891943e-04   6.34319877e-05   5.08239737e-06   7.37158535e-03\n",
      "   8.19764755e-05   4.43822271e-11   8.59137217e-05   3.74288560e-04\n",
      "   4.72034840e-03   9.45571251e-03   1.66345548e-04   9.90492772e-05\n",
      "   3.05705253e-11   4.29729884e-03   3.84823303e-03   3.05350148e-03\n",
      "   9.95690357e-07   1.40468075e-07   2.74201466e-06   2.21293931e-07\n",
      "   6.29744157e-02   1.76291650e-07   2.51977828e-13   5.03653008e-10\n",
      "   9.58128195e-12   1.55694888e-08   3.01264916e-11   3.36081965e-12\n",
      "   4.33935830e-03   8.62652235e-14   2.87324869e-11   1.69470937e-07\n",
      "   5.03143951e-07   1.65470235e-10   7.46176732e-12   2.50213609e-12\n",
      "   3.19921566e-14   8.13184686e-10   3.19467529e-16   3.52353975e-12\n",
      "   6.08834649e-10   1.63117397e-06   1.43129719e-09]\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "# test_start = \"STAN I said 'We're not getting on, you fat ugly bitch'.\"[:50]\n",
    "# section = [test_start]\n",
    "prediction_length = 5000\n",
    "epoch_test = get_latest_epoch()\n",
    "print(\"Testing epoch: {}\".format(epoch_test))\n",
    "#\n",
    "\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess,\"./model/model.ckpt-\"+str(epoch_test))\n",
    "    start_index = random.randint(0, len(text) - section_length - 1)\n",
    "    test_start = text[start_index: start_index + section_length]\n",
    "    \n",
    "    X_test = np.zeros((1,section_length,vocab_length))\n",
    "    for i,c in enumerate(test_start):\n",
    "        X_test[0,i,characters2id[c]]=1\n",
    "    \n",
    "    for temperature in [0.2]:\n",
    "        print(\"Temperature = {}\".format(temperature))\n",
    "        \n",
    "        print(test_start,end=\"\")\n",
    "        for _ in range(prediction_length): \n",
    "            pred = sess.run(prediction,feed_dict={X:X_test})\n",
    "            pred = pred.reshape(-1)\n",
    "#             pred = sample2(pred,temperature)\n",
    "            next_char = id2characters[np.argmax(pred)]\n",
    "            print(np.argmax(pred),max(pred))\n",
    "            print(pred)\n",
    "            break\n",
    "            test_start += next_char\n",
    "            print(next_char,end=\"\")\n",
    "            \n",
    "            test_start = test_start[-section_length:]\n",
    "            X_test = np.zeros((1,section_length,vocab_length))\n",
    "            for i,c in enumerate(test_start):\n",
    "                X_test[0,i,characters2id[c]]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
